{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Define the transformation for the training set (with data augmentation)\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.RandomAffine(0, shear=10, scale=(0.8, 1.2)),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Define the transformation for the validation set (without augmentation)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "# Load CIFAR-10 dataset with transformations\n",
    "training_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "validation_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Data loaders\n",
    "training_loader = torch.utils.data.DataLoader(training_dataset, batch_size=100, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=100, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CNN MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        \n",
    "        # Convolutional Layers with Batch Normalization\n",
    "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3, padding=1)  # Input channels: 3, Output channels: 64\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(64, 128, kernel_size=3, padding=1)  # Input channels: 64, Output channels: 128\n",
    "        self.bn2 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(128, 256, kernel_size=3, padding=1)  # Input channels: 128, Output channels: 256\n",
    "        self.bn3 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        # Pooling Layer\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # Fully Connected Layers\n",
    "        self.fc1 = nn.Linear(256 * 4 * 4, 1024)  # Input size: 256x4x4, Output size: 1024\n",
    "        self.bn_fc1 = nn.BatchNorm1d(1024)\n",
    "        \n",
    "        self.fc2 = nn.Linear(1024, 10)  # Output size: 10 (number of classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.bn1(self.conv1(x))))\n",
    "        x = self.pool(F.relu(self.bn2(self.conv2(x))))\n",
    "        x = self.pool(F.relu(self.bn3(self.conv3(x))))\n",
    "        \n",
    "        # Flatten the image\n",
    "        x = x.view(-1, 256 * 4 * 4)\n",
    "        \n",
    "        # Fully connected layers with Batch Normalization\n",
    "        x = F.relu(self.bn_fc1(self.fc1(x)))\n",
    "        \n",
    "        x = self.fc2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MODEL LOADING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\7501\\AppData\\Local\\Temp\\ipykernel_21984\\1076258511.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model_final.pth\"))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (fc1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "  (bn_fc1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=1024, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model architecture\n",
    "model = CNN()\n",
    "\n",
    "# Load the trained model's state dict\n",
    "model.load_state_dict(torch.load(\"best_model_final.pth\"))\n",
    "\n",
    "# Ensure the model is in evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LATENCY OF PYTORCH MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Average Latency: 0.156344 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Function to measure PyTorch latency with a batch of validation data\n",
    "def measure_pytorch_latency(model, data_loader, num_runs=100):\n",
    "    latencies = []\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device  # Get the device of the model\n",
    "    with torch.no_grad():\n",
    "        for _ in range(num_runs):\n",
    "            inputs, _ = next(iter(data_loader))  # Take a batch of validation data\n",
    "            inputs = inputs.to(device)  # Move inputs to the same device as the model\n",
    "            start_time = time.time()\n",
    "            _ = model(inputs)  # Forward pass\n",
    "            latencies.append(time.time() - start_time)\n",
    "    return latencies\n",
    "\n",
    "# Load your model (replace with your actual model)\n",
    "pytorch_latencies = measure_pytorch_latency(model, validation_loader)\n",
    "pytorch_avg_latency = np.mean(pytorch_latencies)\n",
    "\n",
    "print(f\"PyTorch Average Latency: {pytorch_avg_latency:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EXPORT PYTORCH TO ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model successfully exported to best_model_final.onnx\n"
     ]
    }
   ],
   "source": [
    "# Assuming the model is loaded as 'model' and 'validation_loader' is defined\n",
    "\n",
    "# Load a batch of validation data\n",
    "inputs, _ = next(iter(validation_loader))  # Get the first batch of data from the validation loader\n",
    "\n",
    "# Export the trained PyTorch model to ONNX using the validation batch\n",
    "onnx_path = \"best_model_final.onnx\"\n",
    "\n",
    "torch.onnx.export(\n",
    "    model,\n",
    "    inputs,  # Use the validation batch as input\n",
    "    onnx_path,\n",
    "    export_params=True,\n",
    "    opset_version=11,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"]\n",
    ")\n",
    "\n",
    "print(f\"Model successfully exported to {onnx_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "model = onnx.load(\"best_model_final.onnx\")\n",
    "onnx.checker.check_model(model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CONVERT ONNX TO TENSORRT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "trtexec --onnx=best_model_final.onnx --saveEngine=best_model_final.trt --fp16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LATENCY FOR TENSORRT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average latency per batch: 0.014679 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import tensorrt as trt\n",
    "\n",
    "# Load the TensorRT engine\n",
    "def load_engine(engine_path):\n",
    "    runtime = trt.Runtime(trt.Logger(trt.Logger.WARNING))\n",
    "    try:\n",
    "        with open(engine_path, 'rb') as f:\n",
    "            engine = runtime.deserialize_cuda_engine(f.read())\n",
    "        if engine is None:\n",
    "            raise ValueError(\"Failed to deserialize the engine.\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading engine: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Perform inference and measure latency\n",
    "def infer_and_measure_latency(engine, validation_loader):\n",
    "    context = engine.create_execution_context()\n",
    "    \n",
    "    # Lists to store input and output bindings\n",
    "    input_bindings = []\n",
    "    output_bindings = []\n",
    "    \n",
    "    # Iterate through all tensors in the engine\n",
    "    for i in range(engine.num_io_tensors):\n",
    "        tensor_name = engine.get_tensor_name(i)\n",
    "        size = trt.volume(engine.get_tensor_shape(tensor_name))  # Get the tensor size (volume)\n",
    "        dtype = trt.nptype(engine.get_tensor_dtype(tensor_name))  # Get the tensor data type\n",
    "        \n",
    "        # Check whether the tensor is an input or output\n",
    "        if engine.get_tensor_mode(tensor_name) == trt.TensorIOMode.INPUT:\n",
    "            input_bindings.append((tensor_name, size, dtype))\n",
    "        else:\n",
    "            output_bindings.append((tensor_name, size, dtype))\n",
    "    \n",
    "    # Assuming the input shape is (batch_size, 3, 32, 32) and output shape is (batch_size, 10)\n",
    "    # You may adjust this based on your model\n",
    "    input_binding = input_bindings[0]  # First input binding\n",
    "    output_binding = output_bindings[0]  # First output binding\n",
    "    \n",
    "    # Get the input shape directly from the engine\n",
    "    input_shape = engine.get_tensor_shape(input_binding[0])\n",
    "    batch_size = input_shape[0]  # The batch size is the first dimension\n",
    "    \n",
    "    # Get the output shape directly from the engine\n",
    "    output_shape = engine.get_tensor_shape(output_binding[0])\n",
    "\n",
    "    # Convert TensorRT Dims to tuple\n",
    "    input_shape_tuple = tuple(input_shape)\n",
    "    output_shape_tuple = tuple(output_shape)\n",
    "\n",
    "    # Allocate host and device buffers\n",
    "    d_input = torch.zeros(input_shape_tuple, dtype=torch.float32).cuda()  # Device input memory on GPU\n",
    "    d_output = torch.zeros(output_shape_tuple, dtype=torch.float32).cuda()  # Device output memory on GPU\n",
    "\n",
    "    latencies = []\n",
    "    for inputs, _ in validation_loader:\n",
    "        inputs = inputs.cuda()  # Move the inputs to GPU\n",
    "        \n",
    "        # Copy inputs to device memory\n",
    "        d_input.copy_(inputs)\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        context.execute_v2([d_input.data_ptr(), d_output.data_ptr()])  # Pass device memory pointers\n",
    "        end_time = time.perf_counter()\n",
    "        \n",
    "        latencies.append(end_time - start_time)\n",
    "    \n",
    "    avg_latency = np.mean(latencies)\n",
    "    return avg_latency\n",
    "\n",
    "# Example usage\n",
    "engine_path = \"best_model_final_1.trt\"\n",
    "engine = load_engine(engine_path)\n",
    "average_latency = infer_and_measure_latency(engine, validation_loader)\n",
    "print(f\"Average latency per batch: {average_latency:.6f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "COMPARISION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot Latency Comparison\n",
    "plt.bar([\"PyTorch\", \"TensorRT\"], [pytorch_avg_latency , average_latency ], color=['blue', 'green'])\n",
    "plt.ylabel(\"Latency (s)\")\n",
    "plt.title(\"Latency Comparison: PyTorch vs TensorRT\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACCURACY VERIFICATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\7501\\AppData\\Local\\Temp\\ipykernel_21984\\1642900474.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model_final.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Model - Validation Loss: 0.5372, Validation Accuracy: 81.50%\n",
      "TensorRT Model - Validation Loss: 0.5372, Validation Accuracy: 81.50%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "\n",
    "# Load the PyTorch model\n",
    "model = CNN()  # Replace with your model class\n",
    "model.load_state_dict(torch.load(\"best_model_final.pth\"))\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Load the TensorRT engine\n",
    "def load_trt_engine(engine_path):\n",
    "    runtime = trt.Runtime(trt.Logger(trt.Logger.WARNING))\n",
    "    try:\n",
    "        with open(engine_path, 'rb') as f:\n",
    "            engine = runtime.deserialize_cuda_engine(f.read())\n",
    "        if engine is None:\n",
    "            raise ValueError(\"Failed to deserialize the engine.\")\n",
    "        return engine\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading engine: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to perform inference with the TensorRT engine\n",
    "def infer_with_trt(engine, validation_loader):\n",
    "    context = engine.create_execution_context()\n",
    "    \n",
    "    # Lists to store input and output bindings\n",
    "    input_bindings = []\n",
    "    output_bindings = []\n",
    "    \n",
    "    # Iterate through all tensors in the engine to retrieve input and output bindings\n",
    "    for i in range(engine.num_io_tensors):\n",
    "        tensor_name = engine.get_tensor_name(i)\n",
    "        size = trt.volume(engine.get_tensor_shape(tensor_name))  # Get tensor size (volume)\n",
    "        dtype = trt.nptype(engine.get_tensor_dtype(tensor_name))  # Get tensor data type\n",
    "        \n",
    "        # Classify the tensor as input or output\n",
    "        if engine.get_tensor_mode(tensor_name) == trt.TensorIOMode.INPUT:\n",
    "            input_bindings.append((tensor_name, size, dtype))\n",
    "        else:\n",
    "            output_bindings.append((tensor_name, size, dtype))\n",
    "    \n",
    "    # Assuming the first input and output binding\n",
    "    input_binding = input_bindings[0]  # First input binding\n",
    "    output_binding = output_bindings[0]  # First output binding\n",
    "    \n",
    "    # Get the input and output shapes directly from the engine\n",
    "    input_shape = engine.get_tensor_shape(input_binding[0])\n",
    "    batch_size = input_shape[0]  # Batch size is the first dimension\n",
    "    output_shape = engine.get_tensor_shape(output_binding[0])\n",
    "\n",
    "    # Convert TensorRT dims to tuple\n",
    "    input_shape_tuple = tuple(input_shape)\n",
    "    output_shape_tuple = tuple(output_shape)\n",
    "\n",
    "    # Allocate device buffers for input and output\n",
    "    d_input = torch.zeros(input_shape_tuple, dtype=torch.float32).cuda()  # Input buffer on GPU\n",
    "    d_output = torch.zeros(output_shape_tuple, dtype=torch.float32).cuda()  # Output buffer on GPU\n",
    "\n",
    "    running_loss = 0.0\n",
    "    running_corrects = 0.0\n",
    "    criterion = torch.nn.CrossEntropyLoss()  # Assuming classification task\n",
    "\n",
    "    for val_inputs, val_labels in validation_loader:\n",
    "        val_inputs = val_inputs.cuda()  # Move to GPU\n",
    "        val_labels = val_labels.cuda()  # Move to GPU\n",
    "\n",
    "        # Copy inputs to device memory\n",
    "        d_input.copy_(val_inputs)\n",
    "        \n",
    "        start_time = time.perf_counter()\n",
    "        \n",
    "        # Run inference\n",
    "        context.execute_v2([d_input.data_ptr(), d_output.data_ptr()])  # Pass device memory pointers\n",
    "        \n",
    "        end_time = time.perf_counter()\n",
    "        \n",
    "        # Convert output to CPU and calculate loss and accuracy\n",
    "        outputs = d_output.cuda()\n",
    "        loss = criterion(outputs, val_labels)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "\n",
    "        running_loss += loss.item() * val_inputs.size(0)\n",
    "        running_corrects += torch.sum(preds == val_labels.data)\n",
    "\n",
    "    # Calculate validation loss and accuracy\n",
    "    num_val_samples = len(validation_loader.dataset)\n",
    "    val_loss = running_loss / num_val_samples\n",
    "    val_acc = (running_corrects.float() / num_val_samples) * 100\n",
    "    \n",
    "    return val_loss, val_acc\n",
    "\n",
    "\n",
    "# Run inference with the PyTorch model\n",
    "def evaluate_pytorch_model():\n",
    "    val_running_loss = 0.0\n",
    "    val_running_corrects = 0.0\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for val_inputs, val_labels in validation_loader:\n",
    "            val_inputs = val_inputs.to(device)\n",
    "            val_labels = val_labels.to(device)\n",
    "            val_outputs = model(val_inputs)\n",
    "            val_loss = criterion(val_outputs, val_labels)\n",
    "            _, val_preds = torch.max(val_outputs, 1)\n",
    "\n",
    "            val_running_loss += val_loss.item() * val_inputs.size(0)\n",
    "            val_running_corrects += torch.sum(val_preds == val_labels.data)\n",
    "    \n",
    "    # Calculate validation loss and accuracy\n",
    "    num_val_samples = len(validation_loader.dataset)\n",
    "    val_loss = val_running_loss / num_val_samples\n",
    "    val_acc = (val_running_corrects.float() / num_val_samples) * 100\n",
    "\n",
    "    return val_loss, val_acc\n",
    "\n",
    "# Load TensorRT model and evaluate\n",
    "engine_path = \"best_model_final_1.trt\"\n",
    "engine = load_trt_engine(engine_path)\n",
    "val_loss_trt, val_acc_trt = infer_with_trt(engine, validation_loader)\n",
    "\n",
    "# Evaluate PyTorch model\n",
    "val_loss_pytorch, val_acc_pytorch = evaluate_pytorch_model()\n",
    "\n",
    "print(f\"PyTorch Model - Validation Loss: {val_loss_pytorch:.4f}, Validation Accuracy: {val_acc_pytorch:.2f}%\")\n",
    "print(f\"TensorRT Model - Validation Loss: {val_loss_trt:.4f}, Validation Accuracy: {val_acc_trt:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
